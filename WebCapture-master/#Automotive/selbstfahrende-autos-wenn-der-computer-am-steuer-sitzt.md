# Selbstfahrende Autos: Wenn der Computer am Steuer sitzt

_Captured: 2017-05-06 at 13:18 from [t3n.de](http://t3n.de/news/selbstfahrende-autos-computer-820488/)_

![    Selbstfahrende Autos: Wenn der Computer am Steuer sitzt
](http://img.t3n.sc/news/wp-content/uploads/2016/07/shutterstock-383436070.jpg?auto=compress%2Cformat&fit=crop&fm=jpg&h=347&ixlib=php-1.1.0&q=65&w=620&s=9c76a5da1c8d5f2dd7aee1b4471fd8cc)

> _ 

(Grafik: [Shutterstock](http://www.shutterstock.com/de/pic-383436070/stock-vector-self-driving-intelligent-driverless-car-goes-through-the-city-with-happy-passenger-relaxing.html?src=XhC7WVnseWGlkly80Z3a0g-1-4))

_

Chris Gerdes denkt viel nach uber Computer auf vier Radern. Also uber selbstfahrende Autos. Sogar dann, wenn er mit dem Rennrad uber die Hugel von San Francisco kurvt. Neulich hatte er wieder so einen Geistesblitz: Die Autos, die ihn uberholten, wichen aus, sie uberfuhren die doppelt durchgezogene Mittellinie. Wurde ein selbstfahrendes Auto das auch tun, fragte er sich. Die kalifornische Straßenverkehrsordnung verbietet das Kreuzen der Mittellinie. Das Computer-Hirn im Fahrzeug wurde sich wohl an die Regeln halten.

„Wir haben hier also ein gelerntes menschliches Verhalten, das gesellschaftlich sogar erwartet wird: Platz machen fur Fahrradfahrer. Das aber eigentlich nicht legal ist", sagt Gerdes, Professor an der Elite-Universitat Stanford. „Wie bringen wir einen solchen erwunschten Regelbruch dem autonomen Auto der Zukunft bei? Und macht die Mittellinie fur ein Roboter-Fahrzeug uberhaupt noch Sinn?"

Gerdes geht davon aus, dass ein autonomes Auto die Situation besser einschatzen kann als jeder Mensch. Der Wagen beobachtet die Umwelt mit Sensoren und Kameras. Das Auto wird den Radfahrer also sowieso nur uberholen, wenn ihm nichts entgegenkommt. Und es wird dem Radler so viel Raum wie moglich geben. Fur Autos ohne Fahrer werden Fahrbahnmarkierungen in Zukunft also womoglich unbedeutend werden.

## Wenn plotzlich jemand vors Auto springt

Gerdes forscht in der US-Technologie-Hochburg, im Silicon Valley, zu selbstfahrenden Autos. Mit Doktoranden steht er regelmaßig an einer Teststrecke. Gerade untersuchen sie, wie Shelley, ein umgerusteter Forschungs-Audi, mit unerwarteten Situationen umgeht.

Zum Beispiel damit, dass hinter jedem am Straßenrand parkenden Auto plotzlich ein erwachsener Fußganger oder gar ein Kind hervorlaufen kann. „Wir werden nie ein perfektes System bauen", raumt Gerdes ein. „Aber wir mussen versuchen, es so sicher wie moglich zu machen."

## Eine Frage fur Philosophen

Bei der muhsamen Kleinarbeit an der Schaltzentrale der Zukunftsautos stellen sich die Forscher viele Fragen. So bekam Gerdes vor einiger Zeit eine E-Mail von Patrick Lin, einem Philosophieprofessor in San Luis Obispo, gelegen auf halber Strecke zwischen San Francisco und Los Angeles. „Denken Sie auch uber all die ethischen Fragen nach, die die autonomen Autos uns bringen werden?", wollte Lin wissen.

Seitdem forschen die beiden Wissenschaftler gemeinsam. Der Philosoph entwirft ein Szenario, der Ingenieur sucht nach technischen Antworten. Zum Beispiel: Stellen wir uns vor, unser Auto kommt in eine Gefahrensituation und kann einem Crash nur noch entgehen, indem es nach links ausweicht. Dort wurde der Wagen eine achtzigjahrige Großmutter toten. Er konnte auch nach rechts umlenken, wo er in ein achtjahriges Madchen steuern wurde. Wie soll das Auto entscheiden?

Der Philosoph Lin sagt: „Es gibt nicht die einzig richtige Antwort hier, das liegt in der Natur des ethischen Dilemmas." Der Autobranche selbst sind solche Fragen spurbar unangenehm. Die Hersteller betonen, Autos wurden nicht dahin programmiert, zwischen Opfertypen zu unterscheiden. Vielmehr sollen die Fahrzeuge jede Kollision vermeiden, erst recht mit ungeschutzten Fußgangern und Radfahrern.

Ein wichtiges Argument fur mehr Sicherheit, wenn der Computer die Kontrolle ubernimmt, ist die traurige Realitat auf den Straßen: Sowohl in den USA als auch in Deutschland ist der Mensch am Steuer fur die Masse der Unfalle verantwortlich. Experten erwarten, dass es durch autonome Fahrzeuge drastisch weniger Unfalle geben wird.

Trotzdem fordert Philosophieprofessor Lin eine gesellschaftliche Diskussion uber die ethischen Fragen: „Wie kommen die Programmierer zu ihrer Entscheidung? Haben sie die Konsequenzen durchdacht?" Lin rat, dass die Autoindustrie uber ethische Fragen offen sprechen sollte. „Macht sie das nicht, wird dieses Informationsvakuum von anderen mit Spekulationen und Ängsten gefullt werden."

  


## Tesla und Google: Der Crash macht unsicher

Fur einen Aufschrei sorgte im Mai 2016 [der erste todliche Unfall mit einem gerade vom Computer gesteuerten Tesla](http://t3n.de/news/ermittlungen-tesla-unfall-787269/) im US-Staat Florida. Der Wagen war nicht komplett autonom, er fuhr im sogenannten Autopilot-Modus. Dabei handelt es sich um ein ausgeklugeltes Assistenzsystem, das vom Fahrer bewusst angeschaltet werden muss und dann unter anderem Spur und Abstand halten soll. Die US-Verkehrsbehorde NHTSA stellte in ihrem Untersuchungsbericht fest, das Assistenzsystem habe wie zugesichert funktioniert, der Fahrer hatte sich aber nicht auf die Technik verlassen durfen.

Auch Roboter-Wagen geraten in Unfalle - meistens fahren unachtsame Menschen auf die korrekt fahrenden Testautos auf. Anfang 2016 jedoch provozierte ein Google-Auto selbst einen Blechschaden, als es beim Umfahren eines Hindernisses einem Bus in den Weg steuerte.

Aktuell sorgt noch fast jeder Zwischenfall fur Schlagzeilen. Experten erwarten, dass diese Phase mit mehr Wagen und immer besserer Technik vergehen wird. 2016 jedoch furchteten sich drei von vier Amerikanern davor, von einem selbstfahrenden Auto durch die Gegend chauffiert zu werden. Bei den Deutschen ist die Skepsis ahnlich groß.

Dabei war es ausgerechnet ein Deutscher, der die Roboter-Wagen-Welle entscheidend anschob: Sebastian Thrun war Professor fur kunstliche Intelligenz in Stanford und entwickelte den autonomen Wagen Stanley auf Basis eines VW Touareg. Spater engagierte ihn Google, um fur den Konzern den ersten Prototypen zu bauen.

Google startete 2009 Tests mit Roboter-Wagen auf der Straße und setzte mit dem Projekt auch etablierte Autokonzerne unter Zugzwang. Seit kurzem stellt die Google-Schwesterfirma Waymo Familien selbstfahrende Minivans fur den Alltag zur Verfugung.

Auch die großen deutschen Autobauer forschen im Silicon Valley und sind mit Testlizenzen unterwegs. So will BMW 2021 gemeinsam mit Intel ein vollautonomes Auto auf die Straße bringen.

Der Mann fur ethische Fragen im BMW-Konzern, Dirk Wisselmann, berichtet, dass man viel an Szenarien arbeite, wie sie der Philosoph Lin entwirft. Zugleich versichert er, dass ein Algorithmus - also eine Computerregel - mit Wertungen wie „Kind geht vor Großmutter" niemals in ein deutsches Auto hinein programmiert werden durfte. „Das verstoßt gegen das Grundgesetz. Die Antwort kann immer nur lauten: Sachschaden vor Personenschaden."

Weil allgemein davon ausgegangen wird, dass vollautonome Wagen oft langsam unterwegs sein werden, sieht Wisselmann keine große Gefahr fur Fußganger. „Bei 30 Kilometer pro Stunde in der Innenstadt ergibt sich ein Bremsweg von etwa 4 Metern. Bei dieser Geschwindigkeit bleiben etwa 50 Zentimeter, die ein Auto nach links oder rechts ausweichen konnte. Also, wie realistisch ist dann ein solch dramatisches Szenario noch?"

## Nicht alles machen, was geht

Mirko Franke, Entwickler bei Bosch, sieht sich starker in der Moral-Zwickmuhle: „Technisch sind wir langst so weit, dass die Sensoren gut erkennen, was sich um das Auto herum tut. Eine etwa einen Meter große Person ist mit hoher Wahrscheinlichkeit ein Kind, jemand mit einem Stock wahrscheinlich ein alterer Mensch." Trotzdem soll das Auto solche Unterschiede nicht berucksichtigen. „Was ethisch ist und was nicht, ist eine gesellschaftliche Frage, das konnen wir nicht als Unternehmen festlegen", betont Franke.

Die Deutschen sind gewohnt vorsichtig. US-Wettbewerber wie Tesla und Waymo wollen sich zum Thema Ethik erst gar nicht außern. Und dann sind da noch die vielen Startups. So wie Peloton. Die Firma entwickelt fuhrerlose Lastwagen fur das sogenannte Platooning. Dabei sollen Fahrzeuge automatisch gesteuert in Kolonne fahren. Software-Entwicklerin Alison Chaiken sagt: „Ingenieure wollen coole Sachen bauen und kummern sich nicht so sehr um die Konsequenzen."

## Ist ein Notfallknopf die Losung?

Nach den ersten Kollisionen wird uber Roboter-Autos zumindest schon diskutiert. Dabei ist oft vom roten Not-Knopf die Rede. Damit konnte der Mensch beim hochautomatisierten Fahren im Krisenfall die Kontrolle wieder ubernehmen. Aber wie realistisch ist das? BMW hat es getestet: „Wir haben uber 400 Fahrsimulationsversuche gemacht, wo wir Realfahrer - naturlich unter Laborbedingungen - mit solchen Situationen konfrontiert haben", sagt Wisselmann.

„Man schickt den Fahrer dabei in die komplette Ablenkung, zum Beispiel liest er ein Buch, wenn plotzlich ein Warnton im Auto ertont. Der Fahrer muss sich dann in kurzester Zeit orientieren und ein Manover einleiten, also bremsen oder ausweichen", so der deutsche Experte. „Die Ergebnisse waren erstaunlich, die Schnellsten brauchten in einfachen Situationen nur zwei bis drei Sekunden."

Stanford-Professor Gerdes halt menschliches Eingreifen dagegen fur keine gute Idee. „Die meisten Unfalle werden heute dadurch verursacht, dass wir Menschen falsch auf unvorhergesehene Situationen reagieren." Mit dem Notfallknopf bekomme man die Kontrolle zum schlechtestmoglichen Zeitpunkt. „Nein, das Auto sollte seine eigenen Entscheidungen treffen konnen oder zu einem sicheren Stand kommen." _dpa_

**Auch spannend: „[Selbstfahrende Autos: Warum du in 30 Jahren nicht mehr selbst fahren darfst](http://t3n.de/news/selbstfahrende-autos-30-jahren-706030/)"**
