# Die Beschleunigung der Intelligenz

_Captured: 2017-04-21 at 14:49 from [www.nzz.ch](https://www.nzz.ch/digital/halbleitertechnik-die-beschleunigung-der-intelligenz-ld.1288113)_

![Google Tensor Processing Unit \(TPU\) \(Bild: PD\)](https://img.nzz.ch/S=W540/O=75/http:/nzz-img.s3.amazonaws.com/2017/4/21/ff834637-6f8d-4d72-9357-abc80f08e5bd.png)

> _Google Tensor Processing Unit (TPU) (Bild: PD)_

Überraschend hat Intel diese Woche bekanntgegeben, dass das traditionsreiche Intel Developer Forum, eine jahrlich stattfindende Fachkonferenz, nicht mehr weitergefuhrt wird. Diese Veranstaltung, die seit zwanzig Jahren jeweils im Sommer stattfindet, wurde von Software-Entwicklern und Hardware-Designern, aber auch von Technikjournalisten sehr geschatzt, weil sie es erlaubte, uber die langfristigen Zukunfttrends der Halbleitertechnik mit jenen Ingenieuren zu diskutieren, die diese Trends gestalten. Doch jetzt, wo nicht mehr klar ist, wie es weitergeht, wo offenbar auch Intel im Nebel stochert, hat diese Fachkonferenz ihre Daseinsberechtigung verloren. Noch vor wenigen Wochen, Ende Marz, hatten hochrangige Intel-Manager an einer anderen Intel-Veranstaltung, dem «[Manufacturing Day»](https://www.intc.com/investor-relations/events-and-presentations/events-calendar/event-details/2017/Intel-Hosted-Event/default.aspx), viel Zukunftsoptimismus verstromt: Das Mooresche Gesetz sei weiterhin und noch lange gultig, die Halbleitertechnik werde sich entlang derselben Linien weiterentwickeln, die seit mehr als 50 Jahren den Lauf der Dinge bestimmten.

## Eine lange Tradition

Unter dem Titel «Cramming More Components onto Integrated Circuits» hat der Intel-Mitbegrunder Gordon Moore vor 52 Jahren in einem Aufsatz die Beobachtung publiziert, dass die Zahl der Transistoren auf einem Chip regelmassig wachst. Der von ihm gewahlte Titel ist geeignet, um das Geschaftsmodell von Intel zu beschreiben; er ist eine Art «vision statement» dieser Halbleiterfirma. Doch seit ein paar Jahren zeigt sich immer deutlicher, dass Intel mit dem «cramming» Muhe hat, dass eine Erhohung der Integrationsdichte immer weniger geeignet ist, um die von den Anwendern geforderte Erhohung der Rechenleistung und der Effizienz zu erzielen. Vor diesem Hintergrund wird verstandlich, warum Softwarefirmen wie [Microsoft](https://www.microsoft.com/en-us/research/project/project-catapult/) und Google angefangen haben, sich mit Halbleitertechnik zu beschaftigen.

Google hat Anfang April in einem [17-seitigen Aufsatz](https://arxiv.org/abs/1704.04760) erstmals detailliert uber die hauseigene Tensor Processing Unit (TPU) informiert. Google verwendet den mathematischen Fachbegriff Tensor im Zusammenhang mit Projekten fur das maschinelle Lernen (ML) im Umfeld von Sprachanalyse und Bildverarbeitung. Die Firma hat vor zwei Jahren mit Tensor Flow eine Sammlung von Programmierhilfen veroffentlicht. Wie jetzt bekannt geworden ist, hat die Firma damals auch begonnen, zur Beschleunigung von mit Tensor Flow entwickelten ML-Anwendungen eigene Halbleiterkomponenten zu entwickeln.

Der Aufsatz uber die Google-TPU, seit einigen Tagen als Vorabdruck auf [Arxiv.org](https://arxiv.org/abs/1704.04760) zuganglich, listet 67 Namen als Autoren auf. Es scheint den Spruch zu bestatigen, wonach es ein ganzes Dorf braucht, um einen Computerchip zu entwerfen, zu verifizieren, zu produzieren und zu testen.

Der erste Name auf der Liste, Norman Jouppi, verweist auf einen altgedienten, renommierten Chip-Designer. Er hat zu Beginn der 1980er Jahre an der Stanford University als Mitarbeiter von John Hennessy eine Prozessorarchitektur namens Reduced Instruction Set Computer (Risc) mitentwickelt. Eine Weile sah es in den 1990er Jahren so aus, als ob Prozessoren dieses Typs als Bestandteil von Unix-Computern von Sun Microsystems, Hewlett-Packard (HP), IBM oder Digital Equipment (Dec) die Intel-Prozessoren bei leistungshungrigen Anwendungen verdrangen konnten. Doch Intel schlug diese Konkurrenz aus dem Feld. Nach Stationen bei Dec, Compaq und HP arbeitet Jouppi seit 2013 bei Google. Ein weiterer illustrer Name unter den TPU-Entwicklern ist David Patterson: Der emeritierte Computerwissenschafter aus Berkeley hat sich ebenfalls mit der Entwicklung von Risc-Prozessoren hervorgetan.

## Smartphones erhohen Druck

Seit mehr als zehn Jahren, so heisst es in dem TPU-Aufsatz, werde bei Google uber die Entwicklung eigener Computerchips diskutiert. 2013 habe sich der Druck, zu handeln, durch die zunehmende Popularitat von ML-Anwendungen erhoht. Wenn jeder Besitzer eines Android-Smartphones die sprachgesteuerte Internetsuche nur drei Minuten pro Tag nutzen wurde, so berechneten Google-Ingenieure, dann musste die Firma ein gutes Dutzend neuer Rechenzentren bauen. Deshalb wurde die Entwicklung eines eigenen Beschleunigers fur ML-Anwendungen in Angriff genommen; das Projekt konnte in nur funfzehn Monaten abgeschlossen werden.

Die TPU wird uber eine gangige Verbindung, Peripheral Component Interconnect Express (PCIe) genannt, in Computersysteme integriert. Die PCIe-Schnittstelle erlaubt es, die TPU wie eine Graphikarte (Graphics Computing Unit, GPU) mit wenigen Handgriffen in herkommliche Computer einzubauen. Die TPU soll den Hauptprozessor (Central Processing Unit, CPU) nicht ersetzen, aber erganzen und unterstutzen, so wie das fruher die auf Gleitkomma-Berechnungen spezialisierten Floating Point Units (FPU) taten. Die TPU sei eher mit einer FPU als mit einer GPU zu vergleichen, schreiben Juppi und seine Kollegen. Die TPU ist fur Verarbeitung von Matrix-Multiplikationen optimiert; sie verfugt uber 65'536 Rechenelemente, die in einem Schritt 8-Bit-Integerwerte multiplizieren oder addieren konnen.

## Beeindruckende Leistung

Die Leistungsdaten, die Jouppi und seine Kollegen vorzeigen konnen, sind beeindruckend. Sie haben die TPU 2015 bei ML-Anwendungen mit einem Haswell-CPU von Intel und mit einer Tesla-K80-GPU von Nvidia verglichen. Die TPU war um den Faktor 15 bis 30 schneller, bei der Effizienz - Rechenleistung in Abhangigkeit vom Stromverbrauch - ist die TPU um den Faktor 30 bis 80 besser als die Konkurrenz.

[Nvidia hat in einer Medienmitteilung](https://blogs.nvidia.com/blog/2017/04/10/ai-drives-rise-accelerated-computing-datacenter/) darauf hingewiesen, die Tesla-K80-GPU langst durch leistungsfahigere Produkte abgelost worden sei. Doch die Medienmitteilung der kalifornischen Halbleiterfirma betont in der Beziehung mit Google weniger das Trennende als vielmehr das Verbindende. Die Messungen der Google-Ingenieure hatten die Einsichten bestatigt, von denen man sich auch bei Nvidia leiten lasse: ML-Anwendungen bestimmten in den Rechenzentren zunehmend die Anforderungen an die Halbleitertechnik, und ML-Anwendungen seien auf spezialisierte Prozessoren angewiesen.

[Laut Jouppi](https://cloudplatform.googleblog.com/2016/05/Google-supercharges-machine-learning-tasks-with-custom-chip.html) besitzt die Google-TPU gegenuber einer Intel-CPU einen Leistungsvorsprung, der drei Mooreschen Miniaturisierungsschritten entspricht. Das bedeutet, dass Intel bestenfalls Mitte der 2020er Jahre in der Lage sein wird, eine CPU herzustellen, die bei ML-Anwendungen mit den TPU von heute Schritt halten kann.

![TPU-beschleunigte Computer in einem Rechenzentrum von Google \(Bild: PD\)](https://img.nzz.ch/S=W540/O=75/http:/nzz-img.s3.amazonaws.com/2017/4/21/d3156e1e-13a8-4189-baea-8e682aa1ead7.png)

> _TPU-beschleunigte Computer in einem Rechenzentrum von Google (Bild: PD)_

Der Google-Chip wird von einem nicht bekannten Hersteller in einem 28-Nanometer-Verfahren produziert und lauft mit einer Taktfrequenz von 700 MHz. Diese Werte sind im Vergleich mit einer Intel-CPU bescheiden und lassen erkennen, dass in den TPU noch viel Verbesserungspotenzial steckt. Heutige Intel-Prozessoren werden in einem 14-Nanometer-Verfahren hergestellt, im laufenden Jahr soll der gemass dem Mooreschen Gesetz langst uberfallige Übergang zu 10 Nanometer erfolgen. Vielleicht wird es in einigen Jahren auch noch 7-Nanometer-Chips geben, ob eine Miniaturisierung daruber hinaus noch moglich ist, wird von ernstzunehmenden Experten bezweifelt.

## Die Herausforderungen der Zukunft

Auch wenn bei Intel hochrangige Manager bei jeder Gelegenheit [das Hohe Lied des Mooreschen Gesetzes](https://newsroom.intel.com/editorials/moores-law-setting-the-record-straight/) singen, so ist es ihnen naturlich nicht entgangen, dass die fur die Geschafte der Firma so zentralen Allzweck-Prozessoren durch anwendungsspezifische Chips herausgefordert werden. Mit «Cramming» allein wird die Firma die Herausforderungen der Zukunft nicht bewaltigen konnen. Um sich breiter aufzustellen, hat Intel in jungster Vergangenheit zahlreiche Firmen ubernommen. Grosse Hoffnungen werden unter anderem auf die Fahigkeiten der kalifornischen Jungfirma Nervana Systems gesetzt, die von Intel im Sommer 2016 ubernommen worden ist. Nervana hat Programmierhilfen fur die Entwicklung von ML-Anwendungen und dazu passende Computerchips entwickelt. Im Marz hat Intel rund um Nervana eine neue Abteilung gegrundet: In der [Intel Artificial Intelligence Products Group](https://newsroom.intel.com/editorials/making-future-starts-with-focus-ai/) sollen alle Aktivitaten der Firma im Bereich der kunstlichen Intelligenz gebundelt werden.
