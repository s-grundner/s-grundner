# Google Reveals Automatic Machine Learning: A.I. Can Create Itself

_Captured: 2017-05-24 at 17:24 from [www.inverse.com](https://www.inverse.com/article/31952-ai-google-machine-learning-automl)_

![Terminator 3](https://fsmedia.imgix.net/19/88/c3/8c/c014/4958/b0c6/3f0d422a810c/terminator-3---rise-of-the-machines-screenshot.jpeg?rect=0%2C22%2C714%2C357&auto=format%2Ccompress&w=650)

This month [Google](https://www.inverse.com/topic/google) revealed a major new approach to A.I. development that seems to call out to the most sensational and apocalyptic predictions in all of science fiction.

Called "[AutoML"](https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html) for "auto-machine learning," it allows one [A.I.](https://www.inverse.com/topic/ai) to become the architect of another, and direct its development without the need for input from a human engineer.

On the surface, that sounds like the sort of thing that could lead to the runaway evolution of the [singularity](https://www.inverse.com/topic/singularity), but it's actually Google's bid to put the incredible power of machine learning in the hands of ordinary humans.

In essence, AutoML's strategy of using neural networks to design other neural networks is familiar; making programs to edit the code of other programs is the _definition_ of machine learning. What makes AutoML new is how early into the process of designing a neural net it begins to intervene; AutoML doesn't just refine simple models that already exist, but _selects_ those models in the first place, and then refines them on its own. In this way, AutoML is a more full-featured version of what _normal_ "ML" was always supposed to be.

![Our GoogleNet architecture. Design of this network required many years of careful experimentation and refinement from initial versions of convolutional architectures.](https://fsmedia.imgix.net/1f/68/3e/1c/6332/42e4/a0d6/bc98c1cf3a33/ourgooglenetarchitecture-design-of-this-network-required-many-years-of-careful-experimentation-an.png?auto=format%2Ccompress&w=700)

> _Our GoogleNet architecture. Design of this network required many years of careful experimentation and refinement from initial versions of convolutional architectures._

In a [blog post](https://blog.google/topics/machine-learning/making-ai-work-for-everyone/) about the project, Google CEO Sundar Pichai said that, "We hope AutoML will take an ability that a few Ph.D.s have today and will make it possible in three to five years for hundreds of thousands of developers to design new neural nets for their particular needs."

A neural net is a computer system modeled after the human brain, commonly illustrated as such:

![A neural network example.](https://fsmedia.imgix.net/assets/43.png?auto=format%2Ccompress&w=560)

> _A neural network example._

It's not that crazy an ambition. Usually, if we want to solve a problem with [machine learning](https://www.inverse.com/topic/machine-learning), a human expert has to provide a starting neural network that is already structured to do the basic _type_ of computation the problem requires. AutoML, on the other hand, tries a number of possibly suitable algorithms, essentially testing totally different neural network architectures, and then scores each against the goal. Without the need for human oversight, over time the process should zero in on both the best mathematical approach to the problem _and_ the best implementation of that approach. The final neural net doesn't have to use just one of these algorithms either, and can include individual elements of multiple, if that's more useful.

In theory, the AutoML approach should be able to design more efficient neural nets, if only for simple problems right now, but in being more efficient those [A.I.](https://www.inverse.com/topic/ai) creations could also be more inscrutable to humans.

That's the crux of Google's [main example](https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html) of AutoML's abilities. Given a large database of images to categorize, it designed a neural net that was similar but slightly superior to the one designed by Google's human engineers. What was so fascinating about this sort of design by proxy is that the engineers looking at AutoML's neural network didn't actually know that the differences between it and their own were really improvements; since they hadn't come up with the neural network themselves, they weren't totally sure at first.

Still, the big goal with AutoML isn't to automate humans out of the development process, or even to make all-new styles of A.I., but to let A.I. continue to revolutionize the world at the same pace we've been enjoying for years now. The sheer difficulty of coding neural networks is [becoming a problem](https://www.youtube.com/watch?v=tOviyUFyt8E) for an industry that runs on abundant talent; AutoML is a bid to lower the bar to entry for the coming generation of prospective [machine learning](https://www.inverse.com/topic/machine-learning) students, at least for the simplest and most common applications.

Taken far beyond its current level of sophistication, AutoML is the start of the same process of extreme democratization that we've seen in normal coding several times, already. HTML has Dreamweaver, and machine learning could soon achieve a similar level of drag-and-drop ease by running a whole suite of A.I.-building A.I. in the mold of AutoML.

So, at the end of the day, it's not so much that AutoML could design better A.I., though it certainly could, but that it could help open up an industry that is becoming desperate for talent. AutoML doesn't have the overall level of theoretical and mathematical brilliance of Google's top engineers -- but regular people can't put Google's top engineers to work on their own problems.

With AutoML, Google is building an A.I. engineer that regular people actually could.

![](https://fsmedia.imgix.net/assets/newsletter/promo-bg-science-innovation.jpg?dpr=2&auto=format%2Ccompress&w=450)
