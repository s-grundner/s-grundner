# Using GitHub as a Data Lake

_Captured: 2018-08-22 at 09:38 from [dzone.com](https://dzone.com/articles/using-github-as-a-data-lake?edition=387221&utm_source=Daily%20Digest&utm_medium=email&utm_campaign=Daily%20Digest%202018-08-20)_

[Hortonworks Sandbox](https://dzone.com/go?i=285437&u=https%3A%2F%2Fhortonworks.com%2Fproducts%2Fsandbox%2F%3Futm_campaign%3Ddzonepre%2Fpostroll%26utm_medium%3Ddisplay%26apos%3B%26utm_source%3Ddzone%26utm_id%3D2216633) for HDP and HDF is your chance to get started on learning, developing, testing and trying out new features. Each [download](https://dzone.com/go?i=285437&u=https%3A%2F%2Fhortonworks.com%2Fproducts%2Fsandbox%2F%3Futm_campaign%3Ddzonepre%2Fpostroll%26utm_medium%3Ddisplay%26apos%3B%26utm_source%3Ddzone%26utm_id%3D2216633) comes preconfigured with interactive tutorials, sample data and developments from the Apache community.

There are many situations where we prefer using Amazon S3 as the destination for our date lakes, but increasingly we are also using GitHub as a data lake destination. While GitHub repositories do have some constraints when compared to Amazon S3, when it comes to specific types of big data projects it also has some significant advantages over Amazon S3. Providing us with a solution that can be checked out, forked, and version controlled, helping us stream the data we need across different applications.

Amazon S3 provides us with an industrial grade solution for streaming data in our data lakes. We are developing a growing number of AWS Lambda serverless apps for streaming data from common API sources into an Amazon S3 data lake. However, we are also developing a line of similar functions that stream the same data into GitHub repositories, providing more of a flexible alternative to developing real-time data lakes. Developing approaches to data storage that will allow developers to craft more precise, potentially distributed, and collaborative data lakes.

Using either the public or private repositories, we reguarly find ourselves turning on streams of data that flow into precise repositories, within coordinated GitHub organizations. Taking real-time data from Twitter, Reddit, Stack Overflow, and other APIs, and streaming it into specific repositories, that can then be checked out by developers in real-time, on specific schedules, or in response to events, and used to train machine learning models, or in any other application. While Amazon S3 and GitHub both have APIs, GitHub has the added Git layer, and the benefits of version control, and the other network effects of using GitHub.

GitHub isn't just for code. You can just as easily manage JSON, CSVs, and YAML data within repositories, turning repos into forkable data lakes. In this continuously deployable and integratable development landscape, data lakes aren't always about big data, it can also be about precise data stores, that can be checked out and used wherever it is needed. Making GitHub, GitLab, Bitbucket, and other source control systems an optimal solution for helping us manage data and to use as a destination for our streaming data lakes.

[Hortonworks Community Connection (HCC)](https://dzone.com/go?i=293443&u=https%3A%2F%2Fcommunity.hortonworks.com%2Findex.html%3Futm_campaign%3Ddzonepre%2Fpostrollv2%26utm_medium%3D3rd-party-resource%26utm_source%3Ddzone%26utm_id%3D2307295) is an online collaboration destination for developers, DevOps, customers and partners to get answers to questions, collaborate on technical articles and share code examples from GitHub. [Join the discussion.](https://dzone.com/go?i=293443&u=https%3A%2F%2Fcommunity.hortonworks.com%2Findex.html%3Futm_campaign%3Ddzonepre%2Fpostrollv2%26utm_medium%3D3rd-party-resource%26utm_source%3Ddzone%26utm_id%3D2307295)
