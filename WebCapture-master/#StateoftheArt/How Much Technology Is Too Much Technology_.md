# How Much Technology Is Too Much Technology?

_Captured: 2015-11-16 at 09:31 from [techcrunch.com](http://techcrunch.com/2015/11/15/how-much-technology-is-too-much-technology/?ncid=rss)_

![](https://tctechcrunch2011.files.wordpress.com/2015/11/photo-06-11-2015-22-02-40.jpg?w=738)

There are many visions of what our hyper-connected future might look like. We're packaged countless variants on the shiny-techie-future vision theme every day as marketing departments lay it on thick to try to put gloss on their latest product and restless grease on the wheels of consumption.

Thing is, these tales of shiny futures are not really that interesting. Given they are artless fictions. What's far more interesting is how technology is being applied in the here and now -- and how it's already interacting with and impacting social structures. And if you look at those tell-tale signs then sure it's possible to extrapolate some possible futures -- some of which really aren't very pretty at all.

Technology replacing humans is one recurrent theme. We can [argue about how many jobs are being destroyed by technology](http://techcrunch.com/2015/07/04/so-about-that-whole-tech-eating-jobs-thing/). But that's sort of missing the point. Given that technology is a tool that people can apply in various ways, the number and type of human jobs that get replaced will, at the end of the day, be determined by us, not by the technology.

Or, more likely, by the companies that apply technology at scale. Look, for example, at supermarkets and big box retailers replacing multiple (human) check out operators with ranks of self-service machines -- with perhaps one solitary human overseer standing silently off to the side.

Or Uber recruiting an entire university robotics department to try to [accelerate the development of driverless cars](http://techcrunch.com/2015/02/02/uber-opening-robotics-research-facility-in-pittsburgh-to-build-self-driving-cars/). Because robots can't [protest a dwindling revenue share](http://www.reuters.com/article/2015/11/12/us-uber-london-protest-idUSKCN0T11QZ20151112). Because robots don't get a revenue share.

But who wants to live in a future where every physical shop (if indeed there are any in such a technology-maximized scenario) is a self-service warehouse where the atoms in the drear air stir only to synthesized thank-yous spat from money-harvesting machines, suffixed by the rustle of a departing plastic bag -- attached to another silent human.

Sure, if all you think about are profit margins you won't find any value in the seasonal tapestry of face-to-face human communication. Or the variable elbow grease of human labour. You'll seek to edit it out as an unpredictable inefficiency. But what happens to society when we trade a person for a button press? Or a human being for a [delivery drone](http://techcrunch.com/2015/09/21/drones-will-deliver-your-pizza-and-much-much-more/)?

What happens when we start to view every interaction as merely a quantifiable string of dollar signs -- allowing 'less human' to mean the same as 'lower cost'?

We as individuals -- and as a society -- are also reduced. Reduced in character, colour, culture, communication, cohesion. There's no shortage of collateral damage if you extrapolate a tech-fueled future that thinks only of maximizing profit margins. So why can we so easily glimpse that possible future? Indeed, why do we keep sketching such dystopic scenarios? Why do we seem convinced technology has to capture and control and do _everything _-- as if we humans are powerless to choose how to use our own tools?

As better minds than mine have [pointed out](http://techcrunch.com/2014/11/02/alain-de-bottons-better-capitalism/), humans are, at base, social creatures, yet we are prone to falling for trivial tricks that would sell us a substitute for the social connection we generally crave. Emollient services that proffer a tech-sanitized workaround for our raw, emotionally fretted edges. So sure it's not always companies hammering the shiny technology wedge between genuine human interactions. Undoubtedly, we do this to ourselves too.

Albeit companies know our weaknesses, and seek to exploit them. They always have. Technology just makes that kind of exploitation insanely scaleable.

Perhaps mass surveillance -- a tech-powered dystopia we are living through right here, right now -- is not _just_ a massive trampling of our human rights, but also a giant red flag reminding humanity of the importance of moderating our consumptive impulses.

Because as well as being social creatures, we are all-too-easy addicts. We can't get enough of a good thing. We don't always know when to stop. Sometimes we need to make ourselves really, really sick before we can be compelled to change our ways. If we learn there's a button we can push to get a treat, we'll push it and push it and push it. And keep pushing it. Our present tense world-view can be made to shrink to fit a button press. Or a[ social network](http://techcrunch.com/2014/02/05/leave-no-trace/).

Point is, a little technology is amazing. But all technology, all the time is dystopia. And strutting and fretting our entire lives digitally is a reduction of the rich possibilities of life beyond the algorithm. Even as the increasingly comprehensive digital footprints we generate are also, clearly, a way too tempting repository for governments and companies to ignore -- and so they do the opposite: lift, store and manipulate the substance of our digital lives at will.

Maybe the appropriate response to being systematically dehumanized by vast technology-powered data-harvesting infrastructures is to act a little more human, be a little less tech obsessed. You know -- buy a book from a second-hand bookshop. Pay with cash. Walk down an unfamiliar street. Order a drink in a place you didn't find beforehand on Foursquare. Talk to a stranger you didn't match with on Tinder. Leave your phone in your pocket -- or better still, at home. Unfold a piece of paper and breathe.

Virtual reality? It can never be a fraction as fascinating as real, lived, actual reality where chaotic possibility is threaded through every undesigned moment -- if only you take the time to lift your eyes off the screen and look around you.

And sure, the GooglesAlphabets and Amazons will promise to 'engineer serendipity'. Or say they can transmute our collective behaviors into a predictive extrapolation they'll claim resembles telepathy -- in a bid to deliver you the thing you're after before you even thought to want it. Of course they will. Because they really want to be able to do this. It's the holy grail of commerce.

If they can digitally steer or synthesize a proto human intention before it's become a fully formed thought chain-linked to a guaranteed transaction they get to win the money-makers' neverending jackpot and laugh all the way to the bank -- until the very last neon light winks out in the Nevada desert.

More realistically the giant data miners of our lives will make algorithms that segment collective human behavior into generalized buckets and apply these stencils over individuals, blurring our detail in the process. Because you can't abstract infinite variety. You can't contain multitudes. You can't synthesize all the shifting shades that will ever be perceived.

And so the strategy of control attempts to use ubiquitous technology to disrupt our attention so we forget to think for ourselves.

Undesigned existence is the real magic. And 'engineered serendipity' is both an oxymoron and a dictatorship of the dreary; a notion created by a confederation of bottom-line bores who have somehow attained far more social control than their pedestrian focus on profit margins should ever have afforded them.

If all you're allowed to be or do or know is what's predetermined by aggregated behavioral patterns parsed by algorithms you might as well be living in a medieval monastery -- just without the vaulted ceiling of mystery that exalted such a prior pre-defined existence.

Remember: the algorithm is not God. It's never been omniscient, and it never will be. The algorithm is just a tool for optimization. And most of the time it's the slave of commerce.

Sure, you can think of technology as a lidless eye -- given how it tends to watch and record what we do. But ceaseless surveillance is not a synonym for supernatural. It's technology applied to constrain and reduce; to turn the creative chaos of possibility into a predictable pipeline that can be controlled or monetized. If you think that sounds like magic you probably need to recalibrate your inner lens.

![surveillance](https://tctechcrunch2011.files.wordpress.com/2015/11/photo-12-11-2015-11-10-31.jpg?w=680&h=680)

So really, as we use and shape technology tools and services, we the people making the tech and buying the tech and living with the tech need to sharpen our focus on what's really important. And what's really true. A 'shiny, hyper-connected future' is meaningless if we don't actually want to live in it. If we as individuals threaded within the fabric of society end up feeling less connected to each other, more dehumanized by the tools we use then why are we buying into the marketing fiction? What's in it for us? What's in it for society as a cohesive whole?

The fiction of the shiny sci-fi future is repackaged and sold to us again and again to try to herd us towards some near term commercial goal. But what's the actual, lived reality of these marketing fictions? Fewer human jobs and more ephemeral employment that rebrands social precariousness as 'choice' and 'flexibility'? Fewer actual human interactions and more synthesized, packaged substitutes that feed off the sense of isolation and dissatisfaction their (over)use cultivates?

Does that sound like a fair trade? In exchange for granting a free pass to an army of digital middlemen to mediate more and more aspects of our lives via their shiny layers we get what -- mild diversion and marginal convenience? Cat GIFs on Facebook and pizza dropping from the sky at the push of a drone-summoning button? Are we really so easily infantalized? Can our inner lives be so cheaply bought?

Thing is, it doesn't have to be technology _or_ people. It's possible to imagine a future where technology works FOR people. Where unchecked software is not eating the world but is applied selectively, by societies, as a tool to help tighten and reinforce the jointed scaffolding of real-world communities. To help build actual connections, not devalue real-world social structures to try to replace them with mediated digital alternatives.

But that means recognizing when it's [necessary to moderate the trajectory of a platform](http://techcrunch.com/2015/11/11/airbnb-city-compact/), say, or shape algorithmic applications with people-focused regulation to ensure valuable social structures aren't ripped out or ripped apart by the indifferent interests of corporate accountancy. And -- as individual users of technology -- recognizing when it's time to leave your phone alone for a bit and talk to the people around you.

If we can find the right balance between technology and society, it's possible to imagine many good things being created by humans using ever more sophisticated tools. But achieving that balance requires continuous sweating toil to define society's red lines -- and the discipline not to be distracted or swayed by the superficial sheen of shiny things.

Hard work for sure, but the kind of socially engaged activity that yields genuinely satisfying rewards -- and benefits the many, not the few.
