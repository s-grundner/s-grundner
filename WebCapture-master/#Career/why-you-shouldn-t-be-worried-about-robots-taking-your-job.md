# Why you shouldn't be worried about robots taking your job

_Captured: 2017-12-07 at 23:15 from [www.campaignlive.com](https://www.campaignlive.com/article/why-shouldnt-worried-robots-taking-job/1451864)_

![](https://cached.imagescaler.hbpl.co.uk/resize/scaleWidth/815/cached.offlinehbpl.hbpl.co.uk/news/SUC/SamuelSnider-Held-20171203090847406.jpg)

The announcement of [Adobe's Project Quick 3D](http://www.youtube.com/watch?v=Fqf7wTFS208) and [Google's AutoDraw](http://www.autodraw.com/) demonstrates that AI and machine learning technologies are quickly finding a home in the creative industry. It begs the question--is creativity still our last bastion of superiority in the battle of man versus machine? Should we the creatives be worried about our place in an AI-obsessed future?

I don't think so.

After all, designers currently use software like Photoshop and After Effects to enhance their thinking--imagine the same process, but with semi-intelligent tools. What if these applications could make us more creative?

**What is AI exactly?  
**Even though it's a field that originated in the 1950s, there are many nuances still: AI could mean everything from the character Samantha in the movie "Her" or Google's ability to detect language on websites. When I say AI, I'm not talking about either of those examples--I'm talking about a variety of algorithms that can essentially see like a human can. That's it.

**AI is learning to see.  
**It might not sound that important, but the ability for machines to see is both impressive and groundbreaking. To a computer, an image of a cat is just a long list of numbers. Where in those numbers is the idea of cat? The most bleeding edge algorithm in computer vision is the convolutional neural network. It's modeled off the visual cortexes of animals, so when interpreting an image of a cat, for example, it learns to recognize features at hierarchical levels, like edge, curve, pointy ear and eventually, cat. In other words, a CNN uses these learned features to actually discern the image of a cat from that list of numbers.

While the ability to see may constitute only a small part of AI, it's already making huge changes in how we work with images.

**AI is understanding content and details.  
**If a machine can see, it can engage in artistic and creative tasks, just like humans. If you ask someone do describe a Van Gogh painting, they might say "wavy lines, bright colors," because we're good at understanding and describing visual content.

Now, if you asked someone, "Can you make my selfie look like a Van Gogh painting?", they'll probably run away. Just because we can describe something, doesn't mean we can reproduce it. But it's different for CNNs.

You've most likely seen [Style Transfer](http://genekogan.com/works/style-transfer/) by now. CNNs can easily break down the style of a Van Gogh painting into components like texture, line and color. They can then find correlations in a photo and express them to be more like a Van Gogh painting. So CNNs can, in fact, make your selfie look like a Van Gogh.

![Via https://github.com/jcjohnson/neural-style](https://cached.offlinehbpl.hbpl.co.uk/news/SUC/richedit/Untitled21.png)

> _Via https://github.com/jcjohnson/neural-style_

**AI is collaborative.  
**Software is becoming something you can bounce ideas off. It's already possible to ask a machine things like:

"[I like this landscape, but could you try it with a sunset?](http://www.youtube.com/watch?v=C9AKL328jSU)"

"[Here, draw it like I showed you.](http://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html)"

"[Color in this sketch for me.](http://affinelayer.com/pixsrv/)"

Speech recognition aside, all of these example are actual requests you can ask a computer to do right now.

**A not so futuristic example  
**A common task in game design or 3D animation is character design. It usually begins with the artists and creative directors gathering reference images that express their vision, a process called moodboarding. These images could be pictures or illustrations that express similar qualities.

After the moodboards are set, it is the task of the concept artist or designer to come up with multiple variations based on these reference images. But what if we could use creative AI to augment this process?

For instance, look at generative adversarial neural networks. These algorithms learn to synthesize new data based on learning the qualities of thousands of examples of input data. A popular data set to train a GAN on is [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html), a database of over 200,000 annotated images of celebrities. The latest [research from NVIDIA](http://research.nvidia.com/publication/2017-10_Progressive-Growing-of) used this data set to generate the following images:

![Via http://research.nvidia.com/publication/2017-10_Progressive-Growing-of](https://cached.offlinehbpl.hbpl.co.uk/news/SUC/richedit/Untitled11.png)

> _Via http://research.nvidia.com/publication/2017-10_Progressive-Growing-of_

These images are not photographs nor are they 3D renderings. They're images generated pixel by pixel by a complex set of neural networks.

But instead of CelebA, imagine a software program where you could feed a GAN all the images from your moodboard, and it generated thousands of high quality images based on your input.

Would this system replace the concept artist or illustrator? No. Instead it would allow the artist to try a multitude of options before committing anything to the screen or paper. It means they could start from a more educated point.

**AI design technologists: the future design unicorns  
**What if future creatives could also design and create their own creative AI software? They would be able to enhance their creative power at will. Think of it like reverse engineering parts of your personal creative process. Speeding things up is just the beginning. You could clone this process and have countless versions working on the same or separate problems simultaneously.

You won't need a PhD to do this. You can simply learn from [vloggers on YouTube](http://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A) or dedicated websites like [Machine Learning For Artists](http://ml4a.github.io/).

But maybe it won't just be designers doing this. The ability to create your own pseudo intelligent programs will be desired by many occupations: perhaps farmers will program applications that monitor aerial photos of their crops, or doctors will write software to enhance details in CT scans.

And as the technology evolves, perhaps machines won't take your job. Instead, you'll design one to help you do your job more effectively.

_Samuel Snider-Held is a creative technologist at MediaMonks._
